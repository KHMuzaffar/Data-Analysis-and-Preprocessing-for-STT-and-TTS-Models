{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ad5ceae-8a3d-40b0-a3ed-414c23ce6a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Audio Files in Subset: 0\n",
      "Missing Transcriptions in Subset: 0\n",
      "                                           client_id  \\\n",
      "0  2160561702bac0e2048d2dc79810c2d8a6e6942a6dcac8...   \n",
      "1  2160561702bac0e2048d2dc79810c2d8a6e6942a6dcac8...   \n",
      "2  2160561702bac0e2048d2dc79810c2d8a6e6942a6dcac8...   \n",
      "3  2160561702bac0e2048d2dc79810c2d8a6e6942a6dcac8...   \n",
      "4  2160561702bac0e2048d2dc79810c2d8a6e6942a6dcac8...   \n",
      "5  2160561702bac0e2048d2dc79810c2d8a6e6942a6dcac8...   \n",
      "6  2160561702bac0e2048d2dc79810c2d8a6e6942a6dcac8...   \n",
      "7  2160561702bac0e2048d2dc79810c2d8a6e6942a6dcac8...   \n",
      "8  2160561702bac0e2048d2dc79810c2d8a6e6942a6dcac8...   \n",
      "9  2160561702bac0e2048d2dc79810c2d8a6e6942a6dcac8...   \n",
      "\n",
      "                                                path  \\\n",
      "0  C:\\Users\\admin\\.cache\\huggingface\\datasets\\dow...   \n",
      "1  C:\\Users\\admin\\.cache\\huggingface\\datasets\\dow...   \n",
      "2  C:\\Users\\admin\\.cache\\huggingface\\datasets\\dow...   \n",
      "3  C:\\Users\\admin\\.cache\\huggingface\\datasets\\dow...   \n",
      "4  C:\\Users\\admin\\.cache\\huggingface\\datasets\\dow...   \n",
      "5  C:\\Users\\admin\\.cache\\huggingface\\datasets\\dow...   \n",
      "6  C:\\Users\\admin\\.cache\\huggingface\\datasets\\dow...   \n",
      "7  C:\\Users\\admin\\.cache\\huggingface\\datasets\\dow...   \n",
      "8  C:\\Users\\admin\\.cache\\huggingface\\datasets\\dow...   \n",
      "9  C:\\Users\\admin\\.cache\\huggingface\\datasets\\dow...   \n",
      "\n",
      "                                               audio  \\\n",
      "0  {'path': 'C:\\Users\\admin\\.cache\\huggingface\\da...   \n",
      "1  {'path': 'C:\\Users\\admin\\.cache\\huggingface\\da...   \n",
      "2  {'path': 'C:\\Users\\admin\\.cache\\huggingface\\da...   \n",
      "3  {'path': 'C:\\Users\\admin\\.cache\\huggingface\\da...   \n",
      "4  {'path': 'C:\\Users\\admin\\.cache\\huggingface\\da...   \n",
      "5  {'path': 'C:\\Users\\admin\\.cache\\huggingface\\da...   \n",
      "6  {'path': 'C:\\Users\\admin\\.cache\\huggingface\\da...   \n",
      "7  {'path': 'C:\\Users\\admin\\.cache\\huggingface\\da...   \n",
      "8  {'path': 'C:\\Users\\admin\\.cache\\huggingface\\da...   \n",
      "9  {'path': 'C:\\Users\\admin\\.cache\\huggingface\\da...   \n",
      "\n",
      "                                            sentence  up_votes  down_votes  \\\n",
      "0        Bugun ertalab Gyotenikiga taklifnoma oldim.         2           0   \n",
      "1  Uning badiiy tasvir imkoniyatlarini rivojlanti...         2           0   \n",
      "2                      Udan ko’ra balandroq joy bor.         2           1   \n",
      "3  Bu jumlada fig‘oni falakka chiqib birikmasi ib...         2           1   \n",
      "4     Bundan tashqari puxta jamlangan kutubxona bor.         2           1   \n",
      "5               Ularni hal qilishni paysalga soladi.         2           0   \n",
      "6    Xullas, qiziq maqola, o‘qishni tavsiya qilaman.         2           0   \n",
      "7         Diningizni kimdan olayotganingizga qarang.         2           0   \n",
      "8                Ota-onasi kitob o‘qigan bolalardir.         2           0   \n",
      "9   Shu tariqa qandaydir ezgu ishni amalga oshirasiz         2           0   \n",
      "\n",
      "        age gender accent locale segment  \n",
      "0  twenties   male            uz          \n",
      "1  twenties   male            uz          \n",
      "2  twenties   male            uz          \n",
      "3  twenties   male            uz          \n",
      "4  twenties   male            uz          \n",
      "5  twenties   male            uz          \n",
      "6  twenties   male            uz          \n",
      "7  twenties   male            uz          \n",
      "8  twenties   male            uz          \n",
      "9  twenties   male            uz          \n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login('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')\n",
    "\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset(\"mozilla-foundation/common_voice_12_0\", \"uz\")\n",
    "\n",
    "# Access the 'train' split\n",
    "train_data = dataset['train']\n",
    "\n",
    "# Select a small subset (first 10 entries)\n",
    "small_subset = train_data.select(range(10))\n",
    "\n",
    "# I convert the small subset to a DataFrame for easier manipulation\n",
    "df_small_subset = pd.DataFrame(small_subset)\n",
    "\n",
    "# Check for missing transcriptions or audio files in the small subset\n",
    "missing_audio = df_small_subset['audio'].isnull().sum()\n",
    "missing_transcriptions = df_small_subset['sentence'].isnull().sum()\n",
    "\n",
    "print(f'Missing Audio Files in Subset: {missing_audio}')\n",
    "print(f'Missing Transcriptions in Subset: {missing_transcriptions}')\n",
    "print(df_small_subset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d0d982f-0819-46dd-829c-dee0ec93b78a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noisy Transcriptions: 8\n"
     ]
    }
   ],
   "source": [
    "# Checking for non-alphanumeric characters in transcriptions\n",
    "small_subset = train_data.select(range(10))\n",
    "df_small_subset = pd.DataFrame(small_subset)\n",
    "noisy_transcriptions = df_small_subset['sentence'].str.contains(r'[^a-zA-Zа-яА-Я0-9\\s]', regex=True).sum()\n",
    "print(f'Noisy Transcriptions: {noisy_transcriptions}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f54d3cc1-8d70-4af5-b87a-2bb0f2ebc1eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low Quality Audio Files: 0\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "\n",
    "# Function to analyze audio quality\n",
    "def check_audio_quality(audio_file):\n",
    "    try:\n",
    "        y, sr = librosa.load(audio_file)\n",
    "        rms = np.mean(librosa.feature.rms(y=y))\n",
    "        duration = librosa.get_duration(y=y, sr=sr)\n",
    "        return rms, duration\n",
    "    except Exception as e:\n",
    "        return None, None\n",
    "\n",
    "audio_quality_info = df_small_subset['audio'].apply(lambda x: check_audio_quality(x['path']))\n",
    "df_small_subset['rms'], df_small_subset['duration'] = zip(*audio_quality_info)\n",
    "\n",
    "# Check for low quality\n",
    "low_quality_audio = df_small_subset[df_small_subset['rms'] < 0.01] \n",
    "print(f'Low Quality Audio Files: {len(low_quality_audio)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a5addaf-c601-4329-8953-539fc6eb0d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df_small_subset.dropna(subset=['audio', 'sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c73992b-f5a1-4c8e-99d4-2f0b03c48fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "# Function to normalize transcriptions\n",
    "def normalize_transcription(transcription):\n",
    "    corrected = str(TextBlob(transcription).correct())\n",
    "    return corrected\n",
    "\n",
    "df_small_subset['sentence'] = df_small_subset['sentence'].apply(normalize_transcription)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ef52ce4f-0ae0-44c7-82ec-a610071f6f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame statistics:\n",
      "        rms duration\n",
      "count     0        0\n",
      "unique    0        0\n",
      "top     NaN      NaN\n",
      "freq    NaN      NaN\n",
      "Number of entries after filtering: 0\n",
      "Filtered DataFrame:\n",
      "Empty DataFrame\n",
      "Columns: [client_id, path, audio, sentence, up_votes, down_votes, age, gender, accent, locale, segment, rms, duration]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "print(\"Original DataFrame statistics:\")\n",
    "print(df_small_subset[['rms', 'duration']].describe())\n",
    "\n",
    "# Filter low-quality audio\n",
    "quality_threshold_rms = 0.01  # Minimum RMS value\n",
    "quality_threshold_duration = 5.0  # Minimum duration in seconds\n",
    "\n",
    "# Filter the DataFrame\n",
    "df_cleaned = df_small_subset[(df_small_subset['rms'] > quality_threshold_rms) & (df_small_subset['duration'] > quality_threshold_duration)]\n",
    "\n",
    "print(f'Number of entries after filtering: {len(df_cleaned)}')\n",
    "print(\"Filtered DataFrame:\")\n",
    "print(df_cleaned)\n",
    "\n",
    "      \n",
    "      \n",
    "# By fixing these data quality issues with methods like filtering and cleaning, \n",
    "# We can make your dataset better for speech-to-text training, ensuring it is clear, consistent, and similar to real-life situations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f21c589-6b5b-4523-b778-2ee30c1bc588",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
